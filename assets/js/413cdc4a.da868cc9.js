"use strict";(self.webpackChunkhelp=self.webpackChunkhelp||[]).push([[2097],{3905:(t,e,n)=>{n.d(e,{Zo:()=>d,kt:()=>c});var a=n(7294);function r(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function l(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,a)}return n}function i(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?l(Object(n),!0).forEach((function(e){r(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function o(t,e){if(null==t)return{};var n,a,r=function(t,e){if(null==t)return{};var n,a,r={},l=Object.keys(t);for(a=0;a<l.length;a++)n=l[a],e.indexOf(n)>=0||(r[n]=t[n]);return r}(t,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(t);for(a=0;a<l.length;a++)n=l[a],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(r[n]=t[n])}return r}var p=a.createContext({}),s=function(t){var e=a.useContext(p),n=e;return t&&(n="function"==typeof t?t(e):i(i({},e),t)),n},d=function(t){var e=s(t.components);return a.createElement(p.Provider,{value:e},t.children)},m="mdxType",u={inlineCode:"code",wrapper:function(t){var e=t.children;return a.createElement(a.Fragment,{},e)}},g=a.forwardRef((function(t,e){var n=t.components,r=t.mdxType,l=t.originalType,p=t.parentName,d=o(t,["components","mdxType","originalType","parentName"]),m=s(n),g=r,c=m["".concat(p,".").concat(g)]||m[g]||u[g]||l;return n?a.createElement(c,i(i({ref:e},d),{},{components:n})):a.createElement(c,i({ref:e},d))}));function c(t,e){var n=arguments,r=e&&e.mdxType;if("string"==typeof t||r){var l=n.length,i=new Array(l);i[0]=g;var o={};for(var p in e)hasOwnProperty.call(e,p)&&(o[p]=e[p]);o.originalType=t,o[m]="string"==typeof t?t:r,i[1]=o;for(var s=2;s<l;s++)i[s]=n[s];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},3217:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>m,contentTitle:()=>s,default:()=>k,frontMatter:()=>p,metadata:()=>d,toc:()=>u});var a=n(7462),r=(n(7294),n(3905));const l=n.p+"assets/images/changing-model-1e3bb1b59a431add4323952b9a348a6a.png";var i=n(7620),o=n(5394);n.p,n.p;const p={sidebar_position:2},s="Models",d={unversionedId:"ai-engine/openai/gpt-models",id:"ai-engine/openai/gpt-models",title:"Models",description:"AI Power supports OpenAI GPT-3, GPT-3.5, and GPT-4 models.",source:"@site/docs/ai-engine/openai/gpt-models.mdx",sourceDirName:"ai-engine/openai",slug:"/ai-engine/openai/gpt-models",permalink:"/docs/ai-engine/openai/gpt-models",draft:!1,editUrl:"https://github.com/aipowerorg/aipowerorg.github.io/edit/main/docs/ai-engine/openai/gpt-models.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"API Key",permalink:"/docs/ai-engine/openai/api-key"},next:{title:"Temperature",permalink:"/docs/ai-engine/openai/temperature"}},m={},u=[{value:"GPT-4o",id:"gpt-4o",level:2},{value:"GPT-4",id:"gpt-4",level:2},{value:"GPT-3.5",id:"gpt-35",level:2},{value:"Model Configuration",id:"model-configuration",level:2},{value:"Changing the GPT Model",id:"changing-the-gpt-model",level:3},{value:"Syncing with the Latest OpenAI Models",id:"syncing-with-the-latest-openai-models",level:3},{value:"Rate Limit Buffer",id:"rate-limit-buffer",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"Content Writing",id:"content-writing",level:3},{value:"Chat Bots",id:"chat-bots",level:3}],g={toc:u},c="wrapper";function k(t){let{components:e,...n}=t;return(0,r.kt)(c,(0,a.Z)({},g,n,{components:e,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"models"},"Models"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"AI Power")," supports OpenAI ",(0,r.kt)("strong",{parentName:"p"},"GPT-3"),", ",(0,r.kt)("strong",{parentName:"p"},"GPT-3.5"),", and ",(0,r.kt)("strong",{parentName:"p"},"GPT-4")," models."),(0,r.kt)("h2",{id:"gpt-4o"},"GPT-4o"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Model"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Max Tokens"),(0,r.kt)("th",{parentName:"tr",align:null},"Training Data"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4o"),(0,r.kt)("td",{parentName:"tr",align:null},"High-intelligence flagship model for complex, multi-step tasks."),(0,r.kt)("td",{parentName:"tr",align:null},"4,096"),(0,r.kt)("td",{parentName:"tr",align:null},"Oct 2023")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4o-mini"),(0,r.kt)("td",{parentName:"tr",align:null},"Affordable and intelligent small model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo."),(0,r.kt)("td",{parentName:"tr",align:null},"16,384"),(0,r.kt)("td",{parentName:"tr",align:null},"Oct 2023")))),(0,r.kt)("h2",{id:"gpt-4"},"GPT-4"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Model"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Max Tokens"),(0,r.kt)("th",{parentName:"tr",align:null},"Training Data"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4"),(0,r.kt)("td",{parentName:"tr",align:null},"More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Still in beta."),(0,r.kt)("td",{parentName:"tr",align:null},"8,192"),(0,r.kt)("td",{parentName:"tr",align:null},"Sep 2021")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4-turbo"),(0,r.kt)("td",{parentName:"tr",align:null},"The latest GPT-4 model with improved instruction following. Returns a maximum of 4,096 output tokens."),(0,r.kt)("td",{parentName:"tr",align:null},"128,000"),(0,r.kt)("td",{parentName:"tr",align:null},"Apr 2023")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4-32k"),(0,r.kt)("td",{parentName:"tr",align:null},"Same capabilities as the base gpt-4 mode but with 4x the context length."),(0,r.kt)("td",{parentName:"tr",align:null},"32,768"),(0,r.kt)("td",{parentName:"tr",align:null},"Up to Sep 2021")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-4-vision"),(0,r.kt)("td",{parentName:"tr",align:null},"Ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens."),(0,r.kt)("td",{parentName:"tr",align:null},"128,000"),(0,r.kt)("td",{parentName:"tr",align:null},"Apr 2023")))),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list ",(0,r.kt)("a",{parentName:"p",href:"https://openai.com/waitlist/gpt-4-api"},"here"),".")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: ",(0,r.kt)("em",{parentName:"p"},'"The model: gpt-4 does not exist"')," or ",(0,r.kt)("em",{parentName:"p"},'"The model: gpt-4-32k does not exist"'),".")),(0,r.kt)("h2",{id:"gpt-35"},"GPT-3.5"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Model"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"),(0,r.kt)("th",{parentName:"tr",align:null},"Max Tokens"),(0,r.kt)("th",{parentName:"tr",align:null},"Training Data"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-3.5-turbo"),(0,r.kt)("td",{parentName:"tr",align:null},"Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003."),(0,r.kt)("td",{parentName:"tr",align:null},"4,096"),(0,r.kt)("td",{parentName:"tr",align:null},"Sep 2021")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-3.5-turbo-16k"),(0,r.kt)("td",{parentName:"tr",align:null},"Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context."),(0,r.kt)("td",{parentName:"tr",align:null},"16,384"),(0,r.kt)("td",{parentName:"tr",align:null},"Sep 2021")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gpt-3.5-turbo-instruct"),(0,r.kt)("td",{parentName:"tr",align:null},"Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions."),(0,r.kt)("td",{parentName:"tr",align:null},"4,096"),(0,r.kt)("td",{parentName:"tr",align:null},"Sep 2021")))),(0,r.kt)("h2",{id:"model-configuration"},"Model Configuration"),(0,r.kt)("p",null,"When our plugin is installed for the first time, it comes with ",(0,r.kt)("strong",{parentName:"p"},"gpt-3.5-turbo")," as the default model. You can change it by selecting it from the ",(0,r.kt)("strong",{parentName:"p"},"Model")," dropdown in the ",(0,r.kt)("strong",{parentName:"p"},"AI Engine")," tab."),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"The ",(0,r.kt)("strong",{parentName:"p"},"Express Mode")," in Content Writer and ",(0,r.kt)("strong",{parentName:"p"},"Auto Content Writer")," both use the models set in the ",(0,r.kt)("strong",{parentName:"p"},"Settings - AI Engine")," tab. Any changes made here will apply to both modules.")),(0,r.kt)("h3",{id:"changing-the-gpt-model"},"Changing the GPT Model"),(0,r.kt)("p",null,"Here are the steps:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Navigate to the plugin menu on your WordPress dashboard."),(0,r.kt)("li",{parentName:"ul"},"Click on the ",(0,r.kt)("strong",{parentName:"li"},"Settings")," page and look for the ",(0,r.kt)("strong",{parentName:"li"},"AI Engine")," tab.")),(0,r.kt)("img",{src:l,width:"700"}),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Click on the ",(0,r.kt)("strong",{parentName:"li"},"Model")," dropdown menu to see the available GPT models."),(0,r.kt)("li",{parentName:"ul"},"Select your desired model."),(0,r.kt)("li",{parentName:"ul"},"Click the ",(0,r.kt)("strong",{parentName:"li"},"Save")," button to save your changes.")),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: ",(0,r.kt)("em",{parentName:"p"},'"The model: gpt-4 does not exist"')," or ",(0,r.kt)("em",{parentName:"p"},'"The model: gpt-4-32k does not exist"'),".")),(0,r.kt)("h3",{id:"syncing-with-the-latest-openai-models"},"Syncing with the Latest OpenAI Models"),(0,r.kt)("p",null,"Use the ",(0,r.kt)("strong",{parentName:"p"},"Sync")," button next to the model dropdown to synchronize the plugin with the latest OpenAI models. If OpenAI releases a new model, you can use this button to update the plugin."),(0,r.kt)("img",{src:i.Z}),(0,r.kt)("p",null,"If your organization has fine-tuned any models, you can find them under the Model dropdown."),(0,r.kt)("h3",{id:"rate-limit-buffer"},"Rate Limit Buffer"),(0,r.kt)("p",null,"Our plugin has a Rate Limit Buffer to manage API requests efficiently. This feature allows you to set a delay (1 to 30 seconds) between API calls to avoid rate limit errors from OpenAI."),(0,r.kt)("img",{src:o.Z}),(0,r.kt)("p",null,"We recommend starting with a 1-second delay and increasing it if needed."),(0,r.kt)("h2",{id:"best-practices"},"Best Practices"),(0,r.kt)("p",null,"For different tasks, different GPT models may be more suitable:"),(0,r.kt)("h3",{id:"content-writing"},"Content Writing"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"GPT-3.5 Turbo"),": Most capable GPT-3.5 model, cost-effective."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"GPT-4"),": More capable than any GPT-3.5 model, able to do more complex tasks.")),(0,r.kt)("h3",{id:"chat-bots"},"Chat Bots"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"GPT-3.5 Turbo"),": Optimized for chat and cost-effective."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"GPT-4"),": More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat.")),(0,r.kt)("p",null,"Choose the model that best fits your needs in terms of capabilities, cost, and availability."))}k.isMDXComponent=!0},7620:(t,e,n)=>{n.d(e,{Z:()=>a});const a=n.p+"assets/images/fine-tuned-models-7c405aa290290bad62db019c1ab690eb.png"},5394:(t,e,n)=>{n.d(e,{Z:()=>a});const a=n.p+"assets/images/rate-limit-buffer-24cead6c90de847467688c35a4fe3a8a.png"}}]);