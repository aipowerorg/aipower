"use strict";(self.webpackChunkhelp=self.webpackChunkhelp||[]).push([[5526],{6790:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>j,contentTitle:()=>p,default:()=>m,frontMatter:()=>x,metadata:()=>s,toc:()=>g});const s=JSON.parse('{"id":"ai-engine/openai/gpt-models","title":"Model & Assistant","description":"AI Power supports OpenAI GPT-3, GPT-3.5, GPT-4, and o1 models.","source":"@site/docs/ai-engine/openai/gpt-models.mdx","sourceDirName":"ai-engine/openai","slug":"/ai-engine/openai/gpt-models","permalink":"/docs/ai-engine/openai/gpt-models","draft":false,"unlisted":false,"editUrl":"https://github.com/aipowerorg/aipowerorg.github.io/edit/main/docs/ai-engine/openai/gpt-models.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"API Key","permalink":"/docs/ai-engine/openai/api-key"},"next":{"title":"Temperature","permalink":"/docs/ai-engine/openai/temperature"}}');var i=t(4848),r=t(8453);const o=t.p+"assets/images/changing-model-463caa4edb38a25d6bf5e3ba53e259d4.png",d=t.p+"assets/images/sync-button-c88d14db7f7edb6ae074174739f66858.png";var l=t(5207),a=t(8148),h=t(601),c=t(8436);const x={sidebar_position:2},p="Model & Assistant",j={},g=[{value:"GPT-4o",id:"gpt-4o",level:2},{value:"GPT-4",id:"gpt-4",level:2},{value:"o1 Models (Beta)",id:"o1-models-beta",level:2},{value:"GPT-3.5",id:"gpt-35",level:2},{value:"Model Configuration",id:"model-configuration",level:2},{value:"Changing a Model",id:"changing-a-model",level:3},{value:"Syncing with the Latest OpenAI Models",id:"syncing-with-the-latest-openai-models",level:3},{value:"Rate Limit Buffer",id:"rate-limit-buffer",level:3},{value:"Assistant Configuration",id:"assistant-configuration",level:2}];function u(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"model--assistant",children:"Model & Assistant"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"AI Power"})," supports OpenAI ",(0,i.jsx)(n.strong,{children:"GPT-3"}),", ",(0,i.jsx)(n.strong,{children:"GPT-3.5"}),", ",(0,i.jsx)(n.strong,{children:"GPT-4"}),", and ",(0,i.jsx)(n.strong,{children:"o1"})," models."]}),"\n",(0,i.jsx)(n.h2,{id:"gpt-4o",children:"GPT-4o"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Max Tokens"}),(0,i.jsx)(n.th,{children:"Training Data"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4o"}),(0,i.jsx)(n.td,{children:"High-intelligence flagship model for complex, multi-step tasks."}),(0,i.jsx)(n.td,{children:"4,096"}),(0,i.jsx)(n.td,{children:"Oct 2023"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4o-mini"}),(0,i.jsx)(n.td,{children:"Affordable and intelligent small model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo."}),(0,i.jsx)(n.td,{children:"16,384"}),(0,i.jsx)(n.td,{children:"Oct 2023"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"gpt-4",children:"GPT-4"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Max Tokens"}),(0,i.jsx)(n.th,{children:"Training Data"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4"}),(0,i.jsx)(n.td,{children:"More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Still in beta."}),(0,i.jsx)(n.td,{children:"8,192"}),(0,i.jsx)(n.td,{children:"Sep 2021"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4-turbo"}),(0,i.jsx)(n.td,{children:"The latest GPT-4 model with improved instruction following. Returns a maximum of 4,096 output tokens."}),(0,i.jsx)(n.td,{children:"128,000"}),(0,i.jsx)(n.td,{children:"Apr 2023"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4-32k"}),(0,i.jsx)(n.td,{children:"Same capabilities as the base gpt-4 mode but with 4x the context length."}),(0,i.jsx)(n.td,{children:"32,768"}),(0,i.jsx)(n.td,{children:"Up to Sep 2021"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-4-vision"}),(0,i.jsx)(n.td,{children:"Ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens."}),(0,i.jsx)(n.td,{children:"128,000"}),(0,i.jsx)(n.td,{children:"Apr 2023"})]})]})]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list ",(0,i.jsx)(n.a,{href:"https://openai.com/waitlist/gpt-4-api",children:"here"}),"."]})}),"\n",(0,i.jsx)(n.admonition,{type:"caution",children:(0,i.jsxs)(n.p,{children:["If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: ",(0,i.jsx)(n.em,{children:'"The model: gpt-4 does not exist"'})," or ",(0,i.jsx)(n.em,{children:'"The model: gpt-4-32k does not exist"'}),"."]})}),"\n",(0,i.jsx)(n.h2,{id:"o1-models-beta",children:"o1 Models (Beta)"}),"\n",(0,i.jsx)(n.p,{children:"The o1 series of large language models are designed with reinforcement learning to perform complex reasoning tasks."}),"\n",(0,i.jsx)(n.p,{children:"These models think before answering, producing a long internal chain of thought to solve challenging problems."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Context window"}),(0,i.jsx)(n.th,{children:"Max output tokens"}),(0,i.jsx)(n.th,{children:"Training data"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"o1-preview"}),(0,i.jsx)(n.td,{children:"A reasoning model designed to solve hard problems across multiple domains. Points to the most recent snapshot of the o1 model."}),(0,i.jsx)(n.td,{children:"128,000 tokens"}),(0,i.jsx)(n.td,{children:"32,768 tokens"}),(0,i.jsx)(n.td,{children:"Up to Oct 2023"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"o1-mini"}),(0,i.jsx)(n.td,{children:"A faster and cheaper reasoning model, particularly good at coding, math, and science. Points to the most recent o1-mini snapshot."}),(0,i.jsx)(n.td,{children:"128,000 tokens"}),(0,i.jsx)(n.td,{children:"65,536 tokens"}),(0,i.jsx)(n.td,{children:"Up to Oct 2023"})]})]})]}),"\n",(0,i.jsx)(n.p,{children:"The o1 models are currently in beta with limited features."}),"\n",(0,i.jsxs)(n.p,{children:["Access is restricted to users in ",(0,i.jsx)(n.strong,{children:"tier 5"})," (check your usage tier ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs/guides/rate-limits/usage-tiers",children:"here"}),"), with low rate limits."]}),"\n",(0,i.jsx)(n.p,{children:"OpenAI is working on adding more features, increasing rate limits, and expanding access to more users in the coming weeks."}),"\n",(0,i.jsx)(n.p,{children:"During the beta phase, several chat completion API parameters and features are not yet available:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Modalities:"})," Text only. Images are not supported."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Message types:"})," Only user and assistant messages are supported. System messages are not."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Streaming:"})," Not supported."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Tools:"})," Function calling, tools, and response format parameters are not supported."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Logprobs:"})," Not supported."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Other API parameters:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"temperature"}),", ",(0,i.jsx)(n.code,{children:"top_p"}),", and ",(0,i.jsx)(n.code,{children:"n"})," are fixed at ",(0,i.jsx)(n.code,{children:"1"}),"."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"presence_penalty"})," and ",(0,i.jsx)(n.code,{children:"frequency_penalty"})," are fixed at ",(0,i.jsx)(n.code,{children:"0"}),"."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Assistants and Batch:"})," These models are not supported in the Assistants API or Batch API."]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"gpt-35",children:"GPT-3.5"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Max Tokens"}),(0,i.jsx)(n.th,{children:"Training Data"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-3.5-turbo"}),(0,i.jsx)(n.td,{children:"Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003."}),(0,i.jsx)(n.td,{children:"4,096"}),(0,i.jsx)(n.td,{children:"Sep 2021"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-3.5-turbo-16k"}),(0,i.jsx)(n.td,{children:"Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context."}),(0,i.jsx)(n.td,{children:"16,384"}),(0,i.jsx)(n.td,{children:"Sep 2021"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"gpt-3.5-turbo-instruct"}),(0,i.jsx)(n.td,{children:"Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions."}),(0,i.jsx)(n.td,{children:"4,096"}),(0,i.jsx)(n.td,{children:"Sep 2021"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"model-configuration",children:"Model Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["When our plugin is installed for the first time, it comes with ",(0,i.jsx)(n.strong,{children:"gpt-3.5-turbo"})," as the default model. You can change it by selecting it from the ",(0,i.jsx)(n.strong,{children:"Model"})," dropdown in the ",(0,i.jsx)(n.strong,{children:"AI Engine"})," tab."]}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["The ",(0,i.jsx)(n.strong,{children:"Express Mode"})," in Content Writer and ",(0,i.jsx)(n.strong,{children:"Auto Content Writer"})," both use the models set in the ",(0,i.jsx)(n.strong,{children:"Settings - AI Engine"})," tab. Any changes made here will apply to both modules."]})}),"\n",(0,i.jsx)(n.h3,{id:"changing-a-model",children:"Changing a Model"}),"\n",(0,i.jsx)(n.p,{children:"Here are the steps:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Navigate to the plugin menu on your WordPress dashboard."}),"\n",(0,i.jsxs)(n.li,{children:["Click on the ",(0,i.jsx)(n.strong,{children:"Dashboard"})," page and look for the ",(0,i.jsx)(n.strong,{children:"AI Settings"})," tab."]}),"\n"]}),"\n",(0,i.jsx)("img",{src:o,width:"700"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Click on the ",(0,i.jsx)(n.strong,{children:"Model"})," dropdown menu to see the available GPT models."]}),"\n",(0,i.jsx)(n.li,{children:"Select your desired model."}),"\n"]}),"\n",(0,i.jsx)(n.admonition,{type:"caution",children:(0,i.jsxs)(n.p,{children:["If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: ",(0,i.jsx)(n.em,{children:'"The model: gpt-4 does not exist"'})," or ",(0,i.jsx)(n.em,{children:'"The model: gpt-4-32k does not exist"'}),"."]})}),"\n",(0,i.jsx)(n.h3,{id:"syncing-with-the-latest-openai-models",children:"Syncing with the Latest OpenAI Models"}),"\n",(0,i.jsxs)(n.p,{children:["Use the ",(0,i.jsx)(n.strong,{children:"Sync"})," button next to the model dropdown to synchronize the plugin with the latest OpenAI models. If OpenAI releases a new model, you can use this button to update the plugin."]}),"\n",(0,i.jsx)("img",{src:d}),"\n",(0,i.jsx)(n.p,{children:"If your organization has fine-tuned any models, you can find them under the Model dropdown."}),"\n",(0,i.jsx)("img",{src:l.A}),"\n",(0,i.jsx)(n.h3,{id:"rate-limit-buffer",children:"Rate Limit Buffer"}),"\n",(0,i.jsx)(n.p,{children:"Our plugin has a Rate Limit Buffer to manage API requests efficiently. This feature allows you to set a delay (1 to 30 seconds) between API calls to avoid rate limit errors from OpenAI."}),"\n",(0,i.jsx)("img",{src:a.A}),"\n",(0,i.jsx)(n.p,{children:"We recommend starting with a 1-second delay and increasing it if needed."}),"\n",(0,i.jsx)(n.h2,{id:"assistant-configuration",children:"Assistant Configuration"}),"\n",(0,i.jsx)(n.p,{children:"Our plugin supports the OpenAI Assistant API, allowing you to create and sync custom assistants for use in your chatbot. Here\u2019s how to configure it:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Create an Assistant on OpenAI"}),(0,i.jsx)(n.br,{}),"\n","Go to ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/assistants/",children:"OpenAI Assistants"})," and create your assistant by providing instructions and uploading any relevant files."]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Sync the Assistant with the Plugin"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Go to the ",(0,i.jsx)(n.strong,{children:"Dashboard"})," in the plugin menu."]}),"\n",(0,i.jsxs)(n.li,{children:["Go to the ",(0,i.jsx)(n.strong,{children:"Chatbot"})," tab."]}),"\n",(0,i.jsxs)(n.li,{children:['Click "Edit" for an existing bot or create a new bot using the ',(0,i.jsx)(n.strong,{children:"Create New Bot"})," button."]}),"\n",(0,i.jsxs)(n.li,{children:["Use the ",(0,i.jsx)(n.strong,{children:"Sync"})," button next to the model list to fetch your assistants from OpenAI."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)("img",{src:h.A,width:"700"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Your assistant will now appear in the model list. Select it to link it to your bot."}),"\n"]}),"\n",(0,i.jsx)("img",{src:c.A,width:"700"}),"\n",(0,i.jsx)(n.p,{children:"That\u2019s it! Your chatbot will now use your custom assistant."})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},601:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/assistant_sync-aa728faa9172e23a875c4d0daa707497.png"},8436:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/assistants-2212c38a8899f20a86b779a699e8c60c.png"},5207:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/fine-tuned-models-bb727533a132cfa7d49a9af839ec754f.png"},8148:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/rate-limit-buffer-baef32368f0047c8a5573761f857dc49.png"},8453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>d});var s=t(6540);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);