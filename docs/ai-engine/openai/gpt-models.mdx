---
sidebar_position: 2
---

import ModelWindow2 from '/img/ai-settings/changing-model.png';
import FineTunedModels from '/img/ai-settings/fine-tuned-models.png';
import RateLimitBuffer from '/img/ai-settings/rate-limit-buffer.png';
import ComparisonTool1 from '/img/comparison-tool/comparison1.png';
import ComparisonTool2 from '/img/comparison-tool/comparison2.png';

# Models

**AI Power** supports OpenAI **GPT-3**, **GPT-3.5** and **GPT-4** models.

## GPT-4o

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4o | Most advanced, multimodal flagship model thatâ€™s cheaper and faster than GPT-4 Turbo.  | 8,192 | Oct 2023 |

## GPT-4

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4 | More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Still in beta. | 8,192 | Sep 2021 |
| gpt-4-turbo | The latest GPT-4 model with improved instruction following. Returns a maximum of 4,096 output tokens.  | 128,000 | Apr 2023 |
| gpt-4-32k | Same capabilities as the base gpt-4 mode but with 4x the context length. | 32,768 | Up to Sep 2021 |
| gpt-4-vision | Ability to understand images, in addition to all other GPT-4 Turbo capabilties. Returns a maximum of 4,096 output tokens.| 128,000 | Apr 2023 |

:::info

GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list [here](https://openai.com/waitlist/gpt-4-api).

:::

:::caution

If you don't have GPT-4 API access and if you select GPT-4 or GPT-4K-32K as your model then you will get *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"* error.

:::

## GPT-3.5

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-3.5-turbo | Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. | 4,096 | Sep 2021 |
| gpt-3.5-turbo-16k | Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context. | 16,384 | Sep 2021 |
| gpt-3.5-turbo-instruct | Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions. | 4,096 | Sep 2021 |


## Model Configuration

When our plugin is installed for the first time, it comes with **gpt-3.5-turbo** as the default model.

However you can change it by selecting it from the **Model** dropdown in the **AI Engine** tab.

:::info

Please be aware that the **Express Mode** in Content Writer and **Auto Content Writer** both use the models set in the **Settings - AI Engine** tab. Any changes made here will apply to both modules.

:::

### Changing the GPT Model

Here are the steps:

- First, navigate to the plugin menu on your WordPress dashboard.
- Click on the **Settings** page and look for the **AI Engine** tab.

<img src={ModelWindow2} width="700" />

- Click on the **Model** dropdown menu to reveal the available GPT models that you can choose from.
- Select your desired model from the list by clicking on it.
- After selecting your model, click on the **Save** button to save your changes.
- Your GPT model will now be changed to the one you selected.

:::info

GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list [here](https://openai.com/waitlist/gpt-4-api).

:::

:::caution

If you don't have GPT-4 API access and if you select GPT-4 or GPT-4K-32K as your model then you will get *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"* error.

:::

### Syncing with the Latest OpenAI Models

You may notice a **Sync** button located next to the model dropdown. This button is used to synchronize the plugin with the most recent version of the OpenAI models. So if OpenAI releases a new model, you can use this button to update the plugin to use the new model.

<img src={FineTunedModels} />

If your organization has fine-tuned any models on specific datasets, you can easily find them under the Model dropdown.

### Rate Limit Buffer

Our plugin provides an option named Rate Limit Buffer to manage API requests more efficiently.

This feature appears as a dropdown menu, allowing users to choose a delay ranging from 1 to 30 seconds.

<img src={RateLimitBuffer} />

Rate Limit Buffer allows for a *brief pause* before initiating another API call.

This delay is necessary due to the [rate limits](https://platform.openai.com/docs/guides/rate-limits) imposed by OpenAI for these particular models.

If you encounter a rate limit error from OpenAI, consider using this feature.

We recommend starting with a minimum sleep time of 1 second and incrementally increasing it until you achieve an optimal balance between responsiveness and avoiding rate limit errors.

## Model Comparison

The Comparison Tool under the **Content Writer - Comparison** tab in the AI Power WordPress plugin enables users to compare the outputs of up to six different language models.

This powerful feature lets you experiment with the models and tweak various parameters to fine-tune the output according to your needs.

### How to Use the Comparison Tool

Follow the steps outlined below to make the most of the Comparison Tool.

- **Navigate to the Comparison Tool**: In your WordPress dashboard, go to the AI Power plugin and click on the **Content Writer - Comparison** tab.
- **Select the Models**: From each model dropdown, select the models you want to compare. The options include GPT-3.5, GPT-4, etc. You can choose different models for each comparison window, up to six.

<img src={ComparisonTool1} width="700" />

- **Select or Create a Prompt**: Use the prompt dropdown to select a ready-to-use prompt. Once selected, it will be appended to the text area below. If you prefer, you can modify the selected prompt or write your own.
- **Adjust Parameters**: For each model, adjust the parameters to suit your needs. The parameters you can adjust include max tokens, temperature, top_p, fp, and pp.
- **Generate Output**: Click the **Generate** button for each model window. If you are comparing four models, for example, you will need to hit the **Generate** button four times.

<img src={ComparisonTool2} width="700" />

- **Review Results**: The results of each model will be displayed in the output area. On the left side of each output, you'll see the token count, cost, duration, and word count. These values can be compared across models to help you decide the best model for your needs.

## Best Practices

For different tasks and requirements, different GPT models may be more suitable. Here are some recommendations based on common use cases:

#### Content Writing
For content writing purposes, the following models are recommended:

- **GPT-3.5 Turbo**: Most capable GPT-3.5 model, cost-effective.
- **GPT-4**: More capable than any GPT-3.5 model, able to do more complex tasks.

#### Chat Bots
For chat bot development, consider using these models:

- **GPT-3.5 Turbo**: Most capable GPT-3.5 model, optimized for chat, and cost-effective.
- **GPT-4**: More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat.

Always keep in mind the specific requirements of your website, and choose the model that best fits your needs in terms of capabilities, cost, and availability.
