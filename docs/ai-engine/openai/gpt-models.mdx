---
sidebar_position: 2
---

import ModelWindow2 from '/img/ai-settings/changing-model.png';
import SyncButton from '/img/ai-settings/sync-button.png';
import FineTunedModels from '/img/ai-settings/fine-tuned-models.png';
import RateLimitBuffer from '/img/ai-settings/rate-limit-buffer.png';
import AssistantSync from '/img/ai-settings/assistant_sync.png';
import Assistants from '/img/ai-settings/assistants.png';

# Model & Assistant

**AI Power** supports OpenAI **GPT-3**, **GPT-3.5**, **GPT-4**, and **o1** models.

## GPT-4o

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4o | High-intelligence flagship model for complex, multi-step tasks. | 4,096 | Oct 2023 |
| gpt-4o-mini | Affordable and intelligent small model for fast, lightweight tasks. GPT-4o mini is cheaper and more capable than GPT-3.5 Turbo. | 16,384 | Oct 2023 |

## GPT-4

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4 | More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Still in beta. | 8,192 | Sep 2021 |
| gpt-4-turbo | The latest GPT-4 model with improved instruction following. Returns a maximum of 4,096 output tokens.  | 128,000 | Apr 2023 |
| gpt-4-32k | Same capabilities as the base gpt-4 mode but with 4x the context length. | 32,768 | Up to Sep 2021 |
| gpt-4-vision | Ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens.| 128,000 | Apr 2023 |

:::info
GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list [here](https://openai.com/waitlist/gpt-4-api).
:::

:::caution
If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"*.
:::

## o1 Models (Beta)

The o1 series of large language models are designed with reinforcement learning to perform complex reasoning tasks. 

These models think before answering, producing a long internal chain of thought to solve challenging problems.

| Model      | Description                                                                                     | Context window | Max output tokens | Training data    |
|------------|-------------------------------------------------------------------------------------------------|----------------|-------------------|------------------|
| o1-preview | A reasoning model designed to solve hard problems across multiple domains. Points to the most recent snapshot of the o1 model. | 128,000 tokens | 32,768 tokens     | Up to Oct 2023   |
| o1-mini    | A faster and cheaper reasoning model, particularly good at coding, math, and science. Points to the most recent o1-mini snapshot.  | 128,000 tokens | 65,536 tokens     | Up to Oct 2023   |


The o1 models are currently in beta with limited features. 

Access is restricted to users in **tier 5** (check your usage tier [here](https://platform.openai.com/docs/guides/rate-limits/usage-tiers)), with low rate limits. 

OpenAI is working on adding more features, increasing rate limits, and expanding access to more users in the coming weeks.

During the beta phase, several chat completion API parameters and features are not yet available:

- **Modalities:** Text only. Images are not supported.
- **Message types:** Only user and assistant messages are supported. System messages are not.
- **Streaming:** Not supported.
- **Tools:** Function calling, tools, and response format parameters are not supported.
- **Logprobs:** Not supported.
- **Other API parameters:** 
    - `temperature`, `top_p`, and `n` are fixed at `1`.
    - `presence_penalty` and `frequency_penalty` are fixed at `0`.
- **Assistants and Batch:** These models are not supported in the Assistants API or Batch API.

## GPT-3.5

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-3.5-turbo | Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. | 4,096 | Sep 2021 |
| gpt-3.5-turbo-16k | Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context. | 16,384 | Sep 2021 |
| gpt-3.5-turbo-instruct | Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions. | 4,096 | Sep 2021 |

## Model Configuration

When our plugin is installed for the first time, it comes with **gpt-3.5-turbo** as the default model. You can change it by selecting it from the **Model** dropdown in the **AI Engine** tab.

:::info
The **Express Mode** in Content Writer and **Auto Content Writer** both use the models set in the **Settings - AI Engine** tab. Any changes made here will apply to both modules.
:::

### Changing a Model

Here are the steps:

- Navigate to the plugin menu on your WordPress dashboard.
- Click on the **Dashboard** page and look for the **AI Settings** tab.

<img src={ModelWindow2} width="700" />

- Click on the **Model** dropdown menu to see the available GPT models.
- Select your desired model.

:::caution
If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"*.
:::

### Syncing with the Latest OpenAI Models

Use the **Sync** button next to the model dropdown to synchronize the plugin with the latest OpenAI models. If OpenAI releases a new model, you can use this button to update the plugin.

<img src={SyncButton} />

If your organization has fine-tuned any models, you can find them under the Model dropdown.

<img src={FineTunedModels} />

### Rate Limit Buffer

Our plugin has a Rate Limit Buffer to manage API requests efficiently. This feature allows you to set a delay (1 to 30 seconds) between API calls to avoid rate limit errors from OpenAI.

<img src={RateLimitBuffer} />

We recommend starting with a 1-second delay and increasing it if needed.

## Assistant Configuration

Our plugin supports the OpenAI Assistant API, allowing you to create and sync custom assistants for use in your chatbot. Here’s how to configure it:

1. **Create an Assistant on OpenAI**  
   Go to [OpenAI Assistants](https://platform.openai.com/assistants/) and create your assistant by providing instructions and uploading any relevant files.

2. **Sync the Assistant with the Plugin**  
   - Go to the **Dashboard** in the plugin menu.
   - Go to the **Chatbot** tab.
   - Click "Edit" for an existing bot or create a new bot using the **Create New Bot** button.
   - Use the **Sync** button next to the model list to fetch your assistants from OpenAI.

<img src={AssistantSync} width="700" />

   - Your assistant will now appear in the model list. Select it to link it to your bot.

<img src={Assistants} width="700" />

That’s it! Your chatbot will now use your custom assistant.
