---
sidebar_position: 2
---

import ModelWindow2 from '/img/ai-settings/changing-model.png';
import FineTunedModels from '/img/ai-settings/fine-tuned-models.png';
import RateLimitBuffer from '/img/ai-settings/rate-limit-buffer.png';
import ComparisonTool1 from '/img/comparison-tool/comparison1.png';
import ComparisonTool2 from '/img/comparison-tool/comparison2.png';

# Models

**AI Power** supports OpenAI **GPT-3**, **GPT-3.5**, and **GPT-4** models.

## GPT-4o

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4o | Most advanced, multimodal flagship model thatâ€™s cheaper and faster than GPT-4 Turbo.  | 8,192 | Oct 2023 |

## GPT-4

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-4 | More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat. Still in beta. | 8,192 | Sep 2021 |
| gpt-4-turbo | The latest GPT-4 model with improved instruction following. Returns a maximum of 4,096 output tokens.  | 128,000 | Apr 2023 |
| gpt-4-32k | Same capabilities as the base gpt-4 mode but with 4x the context length. | 32,768 | Up to Sep 2021 |
| gpt-4-vision | Ability to understand images, in addition to all other GPT-4 Turbo capabilities. Returns a maximum of 4,096 output tokens.| 128,000 | Apr 2023 |

:::info
GPT-4 is currently in limited beta, which means that access to the GPT-4 API from OpenAI is available only through a waiting list and is not open to everyone yet. You can sign up for the waiting list [here](https://openai.com/waitlist/gpt-4-api).
:::

:::caution
If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"*.
:::

## GPT-3.5

| Model | Description | Max Tokens | Training Data |
| ----- | ----------- | ---------- | ------------- |
| gpt-3.5-turbo | Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. | 4,096 | Sep 2021 |
| gpt-3.5-turbo-16k | Same capabilities as the standard gpt-3.5-turbo model but with 4 times the context. | 16,384 | Sep 2021 |
| gpt-3.5-turbo-instruct | Similar capabilities as text-davinci-003 but compatible with legacy Completions endpoint and not Chat Completions. | 4,096 | Sep 2021 |

## Model Configuration

When our plugin is installed for the first time, it comes with **gpt-3.5-turbo** as the default model. You can change it by selecting it from the **Model** dropdown in the **AI Engine** tab.

:::info
The **Express Mode** in Content Writer and **Auto Content Writer** both use the models set in the **Settings - AI Engine** tab. Any changes made here will apply to both modules.
:::

### Changing the GPT Model

Here are the steps:

- Navigate to the plugin menu on your WordPress dashboard.
- Click on the **Settings** page and look for the **AI Engine** tab.

<img src={ModelWindow2} width="700" />

- Click on the **Model** dropdown menu to see the available GPT models.
- Select your desired model.
- Click the **Save** button to save your changes.

:::caution
If you don't have GPT-4 API access and select GPT-4 or GPT-4-32K, you will get an error: *"The model: gpt-4 does not exist"* or *"The model: gpt-4-32k does not exist"*.
:::

### Syncing with the Latest OpenAI Models

Use the **Sync** button next to the model dropdown to synchronize the plugin with the latest OpenAI models. If OpenAI releases a new model, you can use this button to update the plugin.

<img src={FineTunedModels} />

If your organization has fine-tuned any models, you can find them under the Model dropdown.

### Rate Limit Buffer

Our plugin has a Rate Limit Buffer to manage API requests efficiently. This feature allows you to set a delay (1 to 30 seconds) between API calls to avoid rate limit errors from OpenAI.

<img src={RateLimitBuffer} />

We recommend starting with a 1-second delay and increasing it if needed.

## Best Practices

For different tasks, different GPT models may be more suitable:

### Content Writing
- **GPT-3.5 Turbo**: Most capable GPT-3.5 model, cost-effective.
- **GPT-4**: More capable than any GPT-3.5 model, able to do more complex tasks.

### Chat Bots
- **GPT-3.5 Turbo**: Optimized for chat and cost-effective.
- **GPT-4**: More capable than any GPT-3.5 model, able to do more complex tasks, and optimized for chat.

Choose the model that best fits your needs in terms of capabilities, cost, and availability.
